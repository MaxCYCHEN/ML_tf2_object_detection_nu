{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Section\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from time import perf_counter\n",
    "\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from ipywidgets import AppLayout, Button, Layout, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference tflite Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Detector():\n",
    "    def __init__(self, tflite_model_loc):\n",
    "        self._max_results = 30\n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilev2_ssd_noopt.tflite', num_threads=4)\n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilev2_ssd_17.tflite', num_threads=4)\n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilev2_ssd_intquant.tflite', num_threads=4)\n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilenetv3_ssd_float.tflite', num_threads=4)\n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilev2_ssd_all_41.tflite', num_threads=4)\n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilev2_ssd_mask_1.tflite', num_threads=4)\n",
    "        \n",
    "        #self._interpreter = tflite.Interpreter(model_path='mobilenetv3_ssd_77367_opt.tflite', num_threads=4)\n",
    "        \n",
    "        self._interpreter = tflite.Interpreter(model_path = tflite_model_loc, num_threads=4)\n",
    "        \n",
    "        input_detail = self._interpreter.get_input_details()[0]\n",
    "        self._interpreter.allocate_tensors()\n",
    "        self._model_input_size = (input_detail['shape'][1], input_detail['shape'][2])\n",
    "    \n",
    "        self._is_quantized_input = input_detail['dtype'] == np.uint8\n",
    "        #print(self._is_quantized_input)\n",
    "\n",
    "        self.scale, self.zero_point = self._interpreter.get_input_details()[0]['quantization']\n",
    "\n",
    "\n",
    "        sorted_output_indices = sorted([output['index'] for output in self._interpreter.get_output_details()])\n",
    "\n",
    "        self._output_indices = {\n",
    "            'BBOX': sorted_output_indices[0],\n",
    "            'CLASS': sorted_output_indices[1],\n",
    "            'SCORE': sorted_output_indices[2],\n",
    "            'VALIDNUM': sorted_output_indices[3], \n",
    "        }\n",
    "\n",
    "    def detect(self, input_image):\n",
    "        input_tensor = self._preprocess(input_image)\n",
    "        self._set_input_tensor(input_tensor)\n",
    "        self._interpreter.invoke()\n",
    "        return self._postprocess()\n",
    "\n",
    "    def _preprocess(self, input_image):\n",
    "        input_tensor = cv2.resize(input_image, self._model_input_size)\n",
    "        \n",
    "        if self._is_quantized_input:\n",
    "            #input_tensor = input_tensor / self.scale + self.zero_point\n",
    "            pass\n",
    "        else:\n",
    "            input_tensor = input_tensor/127.5-1\n",
    "\n",
    "        return np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "    def _set_input_tensor(self, image):\n",
    "        tensor_index = self._interpreter.get_input_details()[0]['index']\n",
    "        input_tensor = self._interpreter.tensor(tensor_index)()[0]\n",
    "        input_tensor[:, :] = image\n",
    "\n",
    "    def _get_output_tensor(self, name):\n",
    "        output_index = self._output_indices[name]\n",
    "        return np.squeeze(self._interpreter.get_tensor(output_index))\n",
    "\n",
    "    def _postprocess(self):\n",
    "        bboxes = self._get_output_tensor('BBOX')[:self._max_results, :] #max\n",
    "        cls = self._get_output_tensor('CLASS')[:self._max_results] #c\n",
    "        scores = self._get_output_tensor('SCORE')[:self._max_results] #b\n",
    "        return bboxes, cls, scores\n",
    "    \n",
    "    def inf_test_tfds(self, dataset_name = \"coco/2017\", split_type=\"validation\", \n",
    "                      NUMPIC = 10, _threshold = 0.5, random_EN = True, _SEED = 3, log_show = False):\n",
    "        [test_dataset], dataset_info = tfds.load(name = dataset_name, split=[split_type], with_info=True)\n",
    "        #[train_dataset], dataset_info_train = tfds.load(name=\"coco/2017\", split=[\"train\"], with_info=True)\n",
    "        #[__test_dataset], dataset_info_test = tfds.load(name=\"coco/2017\", split=[\"test\"], with_info=True)\n",
    "        #test_pct_ds = tfds.load(name=\"coco/2017\", split='validation[50%:70%]') # choose the percent range\n",
    "        \n",
    "        print(len(test_dataset))\n",
    "        labelMap_Func = dataset_info.features[\"objects\"][\"label\"].int2str\n",
    "        colors = np.random.rand(200, 3)*255\n",
    "        \n",
    "        score_threshold = _threshold\n",
    "        TimeBench = {'FPS_Inf':0.0}\n",
    "        #Test_Set = test_dataset\n",
    "        \n",
    "        if random_EN:\n",
    "            shuffle_buffer_size = len(test_dataset)\n",
    "        else:\n",
    "            shuffle_buffer_size = 1\n",
    "      \n",
    "        count_det = 0\n",
    "        #while count_det < NUMPIC:\n",
    "        for sample in test_dataset.shuffle(buffer_size = shuffle_buffer_size, seed = _SEED).take(len(test_dataset)):\n",
    "            \n",
    "            if(count_det >= NUMPIC):\n",
    "                break\n",
    "            \n",
    "            if (0 in sample['objects']['label'].numpy()) or split_type==\"test\": #check only the pictures which have obj we want\n",
    "               \n",
    "                plt.figure(figsize=(12,12))\n",
    "                orignal_image = sample['image'].numpy()\n",
    "                input_img = orignal_image\n",
    "                \n",
    "                ground_truth = sample['objects']['bbox']\n",
    "                \n",
    "                detection_start = perf_counter()\n",
    "                bboxes, classes, scores = self.detect(input_img)\n",
    "                if log_show:\n",
    "                    print(\"bboxes: {}\".format(bboxes))\n",
    "                    print(\"classes: {}\".format(classes))\n",
    "                    print(\"scores: {}\".format(scores))\n",
    "                \n",
    "                detection_end = perf_counter()\n",
    "                \n",
    "                TimeBench['FPS_Inf'] += (detection_end - detection_start)\n",
    "                for bbox, cls, score in zip(bboxes, classes, scores):\n",
    "                    y1, x1, y2, x2 = bbox\n",
    "                    \n",
    "                    if score < score_threshold:\n",
    "                        break\n",
    "                    x1 = int(x1*orignal_image.shape[1])\n",
    "                    x2 = int(x2*orignal_image.shape[1])\n",
    "                    y1 = int(y1*orignal_image.shape[0])\n",
    "                    y2 = int(y2*orignal_image.shape[0])\n",
    "                    _text = '{}_{:.2f}'.format(labelMap_Func(int(cls)), score)\n",
    "                    #_text = '{:.2f}'.format(score)\n",
    "                    cv2.rectangle(orignal_image, (x1, y1), (x2, y2), colors[int(cls)], 1)\n",
    "                    cv2.putText(orignal_image, _text, (x1,y1+10), cv2.FONT_HERSHEY_COMPLEX, 0.4, colors[int(cls)], thickness=1, lineType=cv2.LINE_AA)\n",
    "                \n",
    "                count_det = count_det + 1\n",
    "                plt.imshow(orignal_image)\n",
    "        if count_det > 0:\n",
    "            print(\"FPS: {}\".format(TimeBench['FPS_Inf']/count_det))\n",
    "        else:\n",
    "            print(r\"The 'count_det' is zero, so there is no pictures that have goals\")\n",
    "    \n",
    "    def _load_image_into_numpy_array(self, image):\n",
    "        (im_width, im_height) = image.size\n",
    "        return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "    \n",
    "    def inf_test_my_dataset(self, dataset_loc, label_map_path, NUMPIC = 10, _threshold = 0.5, random_EN = True, _SEED = 3):\n",
    "        inf_num = NUMPIC\n",
    "        score_threshold = _threshold\n",
    "        TimeBench = {'FPS_Inf':0.0}\n",
    "        \n",
    "        TEST_IMAGE_PATHS = glob.glob(dataset_loc)\n",
    "        print('The number of all test image set is: {}'.format(len(TEST_IMAGE_PATHS)))\n",
    "        print('The number of test image this time is: {}'.format(inf_num))\n",
    "        if random_EN:\n",
    "            random.seed(_SEED)\n",
    "            random.shuffle(TEST_IMAGE_PATHS)\n",
    "        TEST_IMAGE_PATHS_INF = TEST_IMAGE_PATHS[:inf_num]\n",
    "        \n",
    "        # map labels for inference decoding\n",
    "        label_map = label_map_util.load_labelmap(label_map_path)\n",
    "        categories = label_map_util.convert_label_map_to_categories(\n",
    "            label_map,\n",
    "            max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "            use_display_name=True)\n",
    "        category_index = label_map_util.create_category_index(categories)\n",
    "        label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n",
    "        \n",
    "        #labelMap_Func = dataset_info.features[\"objects\"][\"label\"].int2str\n",
    "        colors = np.random.rand(200, 3)*255\n",
    "        \n",
    "        for image_path in TEST_IMAGE_PATHS_INF:\n",
    "            \n",
    "            image = Image.open(image_path)\n",
    "            plt.figure(figsize=(12,12))\n",
    "            \n",
    "            input_img = self._load_image_into_numpy_array(image)\n",
    "            \n",
    "            #ground_truth = sample['objects']['bbox']\n",
    "            orignal_image = input_img\n",
    "            \n",
    "            detection_start = perf_counter()\n",
    "            bboxes, classes, scores = self.detect(input_img)\n",
    "            #print(\"bboxes: {}\".format(bboxes))\n",
    "            #print(\"classes: {}\".format(classes))\n",
    "            #print(\"scores: {}\".format(scores))\n",
    "            \n",
    "            detection_end = perf_counter()\n",
    "            \n",
    "            TimeBench['FPS_Inf'] += (detection_end - detection_start)\n",
    "            for bbox, cls, score in zip(bboxes, classes, scores):\n",
    "                y1, x1, y2, x2 = bbox\n",
    "                \n",
    "                if score < score_threshold:\n",
    "                    break\n",
    "                x1 = int(x1*orignal_image.shape[1])\n",
    "                x2 = int(x2*orignal_image.shape[1])\n",
    "                y1 = int(y1*orignal_image.shape[0])\n",
    "                y2 = int(y2*orignal_image.shape[0])\n",
    "                _text = '{}_{:.2f}'.format(category_index[(cls+1)]['name'], score)\n",
    "                #_text = '{:.2f}'.format(score)\n",
    "                cv2.rectangle(orignal_image, (x1, y1), (x2, y2), colors[int(cls)], 1)\n",
    "                cv2.putText(orignal_image, _text, (x1,y1+10), cv2.FONT_HERSHEY_COMPLEX, 0.4, colors[int(cls)], thickness=1, lineType=cv2.LINE_AA)\n",
    "            \n",
    "            plt.imshow(orignal_image)\n",
    "        \n",
    "        if len(TEST_IMAGE_PATHS_INF) > 0:\n",
    "            print(\"Time per plot: {}\".format(TimeBench['FPS_Inf']/len(TEST_IMAGE_PATHS_INF)))\n",
    "        else:\n",
    "            print(r\"There is no pictures that have goals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets.widgets.interaction import show_inline_matplotlib_plots\n",
    "\n",
    "%matplotlib inline\n",
    "class init_inference_tflite_widgets():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.tflite_file_loc = \"\"\n",
    "        \n",
    "        form_item_layout = Layout(\n",
    "        display='flex',\n",
    "        flex_flow='row',\n",
    "        justify_content='space-between',\n",
    "        )\n",
    "        \n",
    "        ### open source data download###\n",
    "        self.A_ta = widgets.Text(value='coco/2017', placeholder='Type something', disabled=False)\n",
    "        self.B_ta = Dropdown(options=['validation', 'test', 'train'])\n",
    "        self.C_ta = widgets.BoundedIntText(value=1, min=0, max=1000, step=1, description='Text:', disabled=False)\n",
    "        self.D_ta = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.02)\n",
    "        self.E_ta = widgets.Checkbox(value=False, disabled=False, indent=False)\n",
    "        self.F_ta = widgets.IntSlider(value=3, min=1, max=100, step=1)\n",
    "        \n",
    "        form_train_items = [\n",
    "            Box([Label(value = 'Dataset Name'), self.A_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Dataset Type'), self.B_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Number of Test'), self.C_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Threshold of Positive'), self.D_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Random Enable'), self.E_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Random Seed'), self.F_ta], layout=form_item_layout)\n",
    "        ]\n",
    "        \n",
    "        self.form_box_train_para = Box(form_train_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightgreen',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "        \n",
    "        ### custom data labeling###\n",
    "        self.A_da = widgets.Textarea(value='C:/Users/USERNAME/image_detection/TensorFlow/workspace/training_demo_8000/images/test/*.jpg', \n",
    "                                     placeholder='Type something', disabled=False)\n",
    "        self.B_da = widgets.Textarea(value='C:/Users/USERNAME/image_detection/TensorFlow/workspace/training_demo_8000/annotations/label_map.pbtxt', \n",
    "                                     placeholder='Type something', disabled=False)\n",
    "        self.C_da = widgets.BoundedIntText(value=10, min=0, max=1000, step=1, description='Text:', disabled=False)\n",
    "        self.D_da = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.02)\n",
    "        self.E_da = widgets.Checkbox(value=False, disabled=False, indent=False)\n",
    "        self.F_da = widgets.IntSlider(value=3, min=1, max=100, step=1)\n",
    "                \n",
    "        form_data_items = [\n",
    "            Box([Label(value = 'Dataset Location'), self.A_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Label Map Location'), self.B_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Number of Test'), self.C_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Threshold of Positive'), self.D_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Random Enable'), self.E_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Random Seed'), self.F_da], layout=form_item_layout)\n",
    "        ]\n",
    "        \n",
    "        self.form_box_data_para = Box(form_data_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightgreen',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "        \n",
    "        ### choose the tflite###\n",
    "        self.A_tfc = widgets.Button(description='tfliteChooser', layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "                \n",
    "        form_data_items = [\n",
    "            Box([Label(value = 'Please Choose tflite model'), self.A_tfc], layout=form_item_layout),\n",
    "        ]\n",
    "        \n",
    "        self.form_box_tflite_load = Box(form_data_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightgreen',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "       \n",
    "        \n",
    "    def move_allfiles(self, src_folder, dst_folder):\n",
    "        copy_num = 0\n",
    "        \n",
    "        files = os.listdir(src_folder)\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(src_folder, f)\n",
    "            if os.path.isdir(fullpath):  #copy whole folder\n",
    "                shutil.move(fullpath, dst_folder)\n",
    "                print(\"Copy finish: {}\".format(f))\n",
    "            \n",
    "    \n",
    "    def show_main(self):   \n",
    "        \n",
    "        intro_text = 'Please Choose the setting of inference data'\n",
    "        htmlWidget = widgets.HTML(value = f\"<b><font color='lightgreen'><font size=4>{intro_text}</b>\")\n",
    "        display(htmlWidget)\n",
    "        \n",
    "        #Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_box_tflite_load, self.form_box_train_para, self.form_box_data_para \n",
    "                                                ]).add_class(\"parentstyle\")\n",
    "        #Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, 'Choose tflite model')\n",
    "        accordion.set_title(1, 'Inference tfds')\n",
    "        accordion.set_title(2, 'Inference my dataset')    \n",
    "        \n",
    "        def act_para(dataset_name, dataset_type, num, th, ran_en, ran_seed,\n",
    "                     dataset_loc, label_map_loc, num_myD, th_myD, ran_en_myD, ran_seed_myD):\n",
    "            #------------------#\n",
    "            # The main executing Toggle_Button\n",
    "            #------------------#\n",
    "            toggle_run_tfds = widgets.ToggleButton(description='Start Inference tfds', \n",
    "                                                   layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            toggle_run_mydataset = widgets.ToggleButton(description='Start Inference my dataset', \n",
    "                                                   layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            out = widgets.Output(layout=Layout(border = '1px solid green'))\n",
    "            \n",
    "            #------------------#\n",
    "            # buttoms event control in widgets.Accordion\n",
    "            #------------------#\n",
    "            def on_button_clicked_tfliteChooser(b):\n",
    "                with out:\n",
    "                    clear_output()\n",
    "                    self.tflite_File_Choose()           \n",
    "            self.A_tfc.on_click(on_button_clicked_tfliteChooser)\n",
    "            \n",
    "            #------------------#\n",
    "            # The main executing Toggle_Button's event function\n",
    "            #------------------#\n",
    "            def run_inference_tfds(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        out.clear_output()\n",
    "                        print('Run tflite test on tfds...')\n",
    "                        \n",
    "                        if (self.tflite_file_loc != \"\"):\n",
    "                            det_obj = Detector(self.tflite_file_loc)\n",
    "                            det_obj.inf_test_tfds(dataset_name, split_type = dataset_type, \n",
    "                                                  NUMPIC = int(num), _threshold = float(th),\n",
    "                                                  random_EN = ran_en, _SEED = int(ran_seed))\n",
    "                            #det_obj.inf_test_tfds(dataset_name = \"coco/2017\", split_type = \"validation\", \n",
    "                            #                      NUMPIC = 1, _threshold = 0.50, random_EN = False, _SEED = 3)\n",
    "                            show_inline_matplotlib_plots()\n",
    "                            print('Finish')\n",
    "                        else:\n",
    "                            print(\"There is no tflite model!!!\")\n",
    "                    else:\n",
    "                        print('stop')\n",
    "                        out.clear_output() \n",
    "            \n",
    "            def run_inference_mydataset(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        out.clear_output()\n",
    "                        print('Run tflite test on my dataset...')\n",
    "                        \n",
    "                        #dataset_loc = \"C:/Users/USERNAME/image_detection/TensorFlow/workspace/training_demo_8000/images/test/*.jpg\"\n",
    "                        #label_map_loc = \"C:/Users/USERNAME/image_detection/TensorFlow/workspace/training_demo_8000/annotations/label_map.pbtxt\"\n",
    "                        \n",
    "                        if (self.tflite_file_loc != \"\"):\n",
    "                            det_obj_mydata = Detector(self.tflite_file_loc)\n",
    "                            det_obj_mydata.inf_test_my_dataset(dataset_loc, label_map_loc, \n",
    "                                                               NUMPIC = int(num_myD), _threshold = float(th_myD), \n",
    "                                                               random_EN = ran_en_myD, _SEED = int(ran_seed_myD))\n",
    "                            show_inline_matplotlib_plots()\n",
    "                            print('Finish')\n",
    "                        else:\n",
    "                            print(\"There is no tflite model!!!\")\n",
    "                    else:\n",
    "                        print('Stop')\n",
    "                        out.clear_output()\n",
    "            \n",
    "            \n",
    "            toggle_run_tfds.observe(run_inference_tfds, 'value')\n",
    "            toggle_run_mydataset.observe(run_inference_mydataset, 'value')\n",
    "            display(toggle_run_tfds, toggle_run_mydataset)\n",
    "            display(out)\n",
    "            \n",
    "        \n",
    "        #------------------#\n",
    "        # widgets.Accordion's interactive input with action function `act_para()`\n",
    "        #------------------#\n",
    "        out_inter = widgets.interactive_output(act_para, {'dataset_name': self.A_ta, 'dataset_type': self.B_ta, 'num': self.C_ta, \n",
    "                                                          'th': self.D_ta, 'ran_en': self.E_ta, 'ran_seed': self.F_ta, \n",
    "                                                          'dataset_loc' : self.A_da, 'label_map_loc' : self.B_da, 'num_myD': self.C_da, \n",
    "                                                          'th_myD' : self.D_da, 'ran_en_myD' : self.E_da, 'ran_seed_myD': self.F_da\n",
    "                                                          })\n",
    "        display(accordion, out_inter)\n",
    "        \n",
    "        \n",
    "    def tflite_File_Choose(self):\n",
    "        path_fc = os.getcwd() ##The image dataset location\n",
    "        path_fc = os.path.join(path_fc, \"tflite_example\")\n",
    "        fc = FileChooser(path_fc)\n",
    "        #fc.show_only_dirs = True\n",
    "        fc.title = f\"<b><font color='lightblue'><font size=4>Choose the tflite.</b>\"\n",
    "        display(fc)\n",
    "        \n",
    "        def act_load_tflite():\n",
    "            self.tflite_file_loc = fc.selected\n",
    "            print(\"Load tflite file: {}\".format(self.tflite_file_loc))\n",
    "            \n",
    "        \n",
    "        evt = interact_manual(act_load_tflite)\n",
    "        evt.widget.children[0].description = 'Load tflite'  #because there are 3 parameter of the evt\n",
    "        evt.widget.children[0].button_style = 'primary'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0595c8ca584c4cbc96f50d55683cf122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightgreen'><font size=4>Please Choose the setting of inference data</b>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd42930767942a4add97fc566be8840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Please Choose tflite model'), Button(button_style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f383ebc1bb412fa5094307398d9c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = init_inference_tflite_widgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edd95acf9ab06b1ecf423b431b914fca015df3a9e640117d0d3acee71022bc47"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
